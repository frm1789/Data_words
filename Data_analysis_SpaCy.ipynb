{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3VFqAJNRoW5uhDgPyGNTR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frm1789/Data_words/blob/main/Data_analysis_SpaCy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How many high frequency words are in a text?\n",
        "In this case, I chose the book \"Dinosaur at dark\" from the well-known series of book, \"The tree magic house\".\n"
      ],
      "metadata": {
        "id": "tvAFO7dBfoSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Import Spacy and setting the language: English."
      ],
      "metadata": {
        "id": "D5GZ3J6kg1X_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "_jgc7YLLvEPl"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Read the text and token it."
      ],
      "metadata": {
        "id": "wBzeemtwg8OP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"text.txt\", \"r\") as f:\n",
        "  content = f.read()\n",
        "  words = content.split()\n",
        "\n",
        "doc = nlp(content)\n",
        "words = [token.text for token in doc]"
      ],
      "metadata": {
        "id": "Bu0lHpVnvSHA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Clean non-alphabetic token\n"
      ],
      "metadata": {
        "id": "vuKq29VuztTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = [word for word in words if word.isalpha()]\n",
        "# len(words) -- 5522"
      ],
      "metadata": {
        "id": "tkv4eoazvGqk"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Count how many unique words appear in the text"
      ],
      "metadata": {
        "id": "eNX5oowmhEsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "word_freq = Counter(words)\n",
        "##print(word_freq)\n",
        "print(\"Total quantity of unique words in text:\", len(word_freq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENnw7UwMvgXR",
        "outputId": "15ae2bd9-1275-419a-8277-2bb3c5b96dac"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total quantity of unique words in text: 1056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) Create a unique list with the high frequency words from Kindergarten to Third Grade"
      ],
      "metadata": {
        "id": "-0oR69JbqFKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hf_K = ['a', 'me', 'to', 'yes', 'big', 'I', 'go', 'in', 'cat', 'for', 'is', 'at', 'on', 'dog', 'he', 'the', 'you', 'like', 'up', 'she', 'mom', 'we', 'my', 'with', 'this', 'dad', 'it', 'by',\n",
        "        'said', 'look', 'can', 'no', 'love', 'play', 'went', 'see', 'am', 'do', 'was', 'and']\n",
        "hf_F = ['after', 'have', 'please', 'all', 'her', 'saw', 'an', 'here', 'should', 'are', 'him', 'so', 'as', 'his', 'some', 'be', 'I’m', 'thank', 'because', 'if', 'that', 'but', 'into', 'them', \n",
        "        'came', 'just', 'then', 'come', 'know', 'they', 'could', 'little', 'there', 'day', 'make', 'us', 'did', 'many', 'very', 'end', 'new', 'want', 'from', 'not', 'were', 'get', 'of', 'what',\n",
        "        'goes', 'one', 'when', 'going', 'or', 'where', 'good', 'our', 'who', 'had', 'out', 'will', 'has', 'over', 'would','your' ]\n",
        "hf_S = ['after', 'have', 'please', 'all', 'her', 'saw', 'an', 'here', 'should', 'are', 'him', 'so', 'as', 'his', 'some', 'be', 'I’m', 'thank', 'because', 'if', 'that', 'but', 'into', 'them', \n",
        "        'came', 'just', 'then', 'come', 'know', 'they', 'could', 'little', 'there', 'day', 'make', 'us', 'did', 'many', 'very', 'end', 'new', 'want', 'from', 'not', 'were', 'get', 'of', 'what',\n",
        "        'goes', 'one', 'when', 'going', 'or', 'where', 'good', 'our', 'who', 'had', 'out', 'will', 'has', 'over', 'would','your' ]\n",
        "hf_T = ['also', 'animal', 'April', 'asked', 'August', 'books', 'brother', 'call', 'care', 'caught', 'caught', 'children', 'city', 'December', 'drink', 'eight', 'eleven',\n",
        "        'ever', 'father', 'favorite', 'February', 'found', 'Friday', 'friend', 'give', 'also', 'animal', 'April', 'asked', 'August', 'books', 'brother', 'call', 'care',\n",
        "        'caught', 'children', 'city', 'December', 'drink', 'eight', 'eleven', 'ever', 'father', 'favorite', 'February', 'found', 'Friday', 'friend', 'give', 'great', \n",
        "        'also' 'animal' 'April', 'asked', 'August', 'books', 'brother', 'call', 'care', 'caught', 'caught', 'children', 'city', 'December', 'drink', 'eight', 'eleven',\n",
        "        'ever', 'father', 'favorite', 'February', 'found', 'Friday', 'friend', 'give', 'great', 'gym', 'half', 'hour', 'hurt', 'January', 'July', 'June', 'kind', 'line', \n",
        "        'mail', 'March', 'May', 'maybe', 'Michigan', 'might', 'Monday', 'mother', 'must', 'night', 'nine', 'November', 'October', 'old', 'other', 'people', 'pretty', 'questions',\n",
        "        'rain', 'rest', 'same', 'Saturday', 'September', 'seven', 'sister', 'snow', 'something', 'stay', 'street', 'such', 'Sunday', 'sure', 'talk', 'teacher', 'tell', \n",
        "        'thing', 'Thursday', 'too', 'Tuesday', 'twelve', 'Wednesday', 'phone']\n"
      ],
      "metadata": {
        "id": "Gvf31s9c1B2s"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_list = hf_K + hf_F + hf_S + hf_T\n",
        "unique_list = list(set(combined_list))\n",
        "unique_list.sort()\n",
        "#print(unique_list)\n",
        "print(\"Total list of word that children learn as high frequency word from Kindergarten to Third Grade: \", len(unique_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsJ2-7-MQyA-",
        "outputId": "26cbe183-484a-4539-819e-15557587a0dc"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total list of word that children learn as high frequency word from Kindergarten to Third Grade:  181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) Count the ocurrence of each of the HF words in the text "
      ],
      "metadata": {
        "id": "P66eSFq8qDk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "filter_word = Counter(word_freq)\n",
        "counts = {word: filter_word[word] for word in combined_list}\n",
        "#print(counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8S8PoUmVPr1",
        "outputId": "ffce7d01-e884-4bfe-a4e7-c1a109da8692"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a': 95, 'me': 4, 'to': 118, 'yes': 0, 'big': 6, 'I': 48, 'go': 13, 'in': 47, 'cat': 0, 'for': 20, 'is': 9, 'at': 55, 'on': 32, 'dog': 5, 'he': 54, 'the': 325, 'you': 31, 'like': 11, 'up': 48, 'she': 32, 'mom': 1, 'we': 17, 'my': 5, 'with': 23, 'this': 14, 'dad': 1, 'it': 46, 'by': 5, 'said': 146, 'look': 9, 'can': 6, 'no': 6, 'love': 0, 'play': 0, 'went': 5, 'see': 11, 'am': 0, 'do': 16, 'was': 100, 'and': 58, 'after': 3, 'have': 5, 'please': 0, 'all': 10, 'her': 35, 'saw': 6, 'an': 5, 'here': 15, 'should': 2, 'are': 8, 'him': 24, 'so': 4, 'as': 10, 'his': 69, 'some': 4, 'be': 8, 'I’m': 0, 'thank': 0, 'because': 0, 'if': 6, 'that': 10, 'but': 0, 'into': 22, 'them': 7, 'came': 3, 'just': 8, 'then': 7, 'come': 3, 'know': 12, 'they': 12, 'could': 14, 'little': 0, 'there': 11, 'day': 0, 'make': 1, 'us': 9, 'did': 7, 'many': 2, 'very': 6, 'end': 0, 'new': 0, 'want': 4, 'from': 11, 'not': 7, 'were': 23, 'get': 6, 'of': 61, 'what': 9, 'goes': 0, 'one': 11, 'when': 2, 'going': 15, 'or': 1, 'where': 4, 'good': 2, 'our': 2, 'who': 5, 'had': 17, 'out': 44, 'will': 0, 'has': 0, 'over': 12, 'would': 3, 'your': 3, 'also': 0, 'animal': 1, 'April': 0, 'asked': 7, 'August': 0, 'books': 13, 'brother': 2, 'call': 2, 'care': 0, 'caught': 1, 'children': 0, 'city': 0, 'December': 0, 'drink': 0, 'eight': 1, 'eleven': 0, 'ever': 3, 'father': 0, 'favorite': 0, 'February': 0, 'found': 5, 'Friday': 0, 'friend': 0, 'give': 0, 'great': 0, 'alsoanimalApril': 0, 'gym': 0, 'half': 1, 'hour': 0, 'hurt': 0, 'January': 0, 'July': 0, 'June': 0, 'kind': 1, 'line': 0, 'mail': 0, 'March': 0, 'May': 0, 'maybe': 1, 'Michigan': 0, 'might': 2, 'Monday': 0, 'mother': 2, 'must': 2, 'night': 0, 'nine': 0, 'November': 0, 'October': 0, 'old': 3, 'other': 6, 'people': 3, 'pretty': 0, 'questions': 0, 'rain': 0, 'rest': 0, 'same': 4, 'Saturday': 0, 'September': 0, 'seven': 2, 'sister': 2, 'snow': 0, 'something': 4, 'stay': 0, 'street': 1, 'such': 0, 'Sunday': 0, 'sure': 4, 'talk': 4, 'teacher': 2, 'tell': 4, 'thing': 1, 'Thursday': 0, 'too': 6, 'Tuesday': 0, 'twelve': 0, 'Wednesday': 0, 'phone': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_count = 0\n",
        "for key, value in counts.items():\n",
        "    total_count += value\n",
        "print(\"\\nTotal quantity of high frequency words in the text: \", total_count)\n",
        "print(\"\\nTotal words of text\", len(words))\n",
        "percentage = total_count/len(words)*100\n",
        "#print(\"\\nTotal words that belongs of the category high frequency words - 1 Grade: \", total)\n",
        "print(\"\\nTotal percentage of words:\", percentage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-bVWp2yVqRY",
        "outputId": "92c3760d-b940-4907-c6ac-4841e8717fb5"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total quantity of high frequency words in the text:  2102\n",
            "\n",
            "Total words of text 5522\n",
            "\n",
            "Total percentage of words: 38.06591814559942\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion:\n",
        "\n",
        "A child in third grade can read 38% of the text.\n",
        "As a side note, third grade is the year when kids go from 'learning to read' to 'reading to learn'.\n",
        "Reading proficiently by the end of third grade is a crucial marker in a child's educational development. Failure to read proficiently is linked to higher rates of school dropout.\n"
      ],
      "metadata": {
        "id": "INjGuhj9qhos"
      }
    }
  ]
}