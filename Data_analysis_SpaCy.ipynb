{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZ/uibkY1L+/uV8Bx6aTHM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frm1789/Data_words/blob/main/Data_analysis_SpaCy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How many high frequency words are in a text?\n",
        "In this case, I chose the book \"Dinosaur at dark\" from the well-known series of book, \"The tree magic house\".\n"
      ],
      "metadata": {
        "id": "tvAFO7dBfoSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Import Spacy and setting the language: English."
      ],
      "metadata": {
        "id": "D5GZ3J6kg1X_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "_jgc7YLLvEPl"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Read the text and token it."
      ],
      "metadata": {
        "id": "wBzeemtwg8OP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"text.txt\", \"r\") as f:\n",
        "  content = f.read()\n",
        "  words = content.split()\n",
        "\n",
        "doc = nlp(content)\n",
        "words = [token.text for token in doc]"
      ],
      "metadata": {
        "id": "Bu0lHpVnvSHA"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Clean non-alphabetic token\n"
      ],
      "metadata": {
        "id": "vuKq29VuztTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = [word for word in words if word.isalpha()]\n",
        "# len(words) -- 5522"
      ],
      "metadata": {
        "id": "tkv4eoazvGqk"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Count how many unique words appear in the text"
      ],
      "metadata": {
        "id": "eNX5oowmhEsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "word_freq = Counter(words)\n",
        "##print(word_freq)\n",
        "print(\"Total quantity of unique words in text:\", len(word_freq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENnw7UwMvgXR",
        "outputId": "b29a5109-635e-4c78-c1ac-f2e83cabc281"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total quantity of unique words in text: 1056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) Create a unique list with the high frequency words from Kindergarten to Third Grade"
      ],
      "metadata": {
        "id": "-0oR69JbqFKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hf_K = ['a', 'me', 'to', 'yes', 'big', 'I', 'go', 'in', 'cat', 'for', 'is', 'at', 'on', 'dog', 'he', 'the', 'you', 'like', 'up', 'she', 'mom', 'we', 'my', 'with', 'this', 'dad', 'it', 'by',\n",
        "        'said', 'look', 'can', 'no', 'love', 'play', 'went', 'see', 'am', 'do', 'was', 'and']\n",
        "hf_F = ['after', 'have', 'please', 'all', 'her', 'saw', 'an', 'here', 'should', 'are', 'him', 'so', 'as', 'his', 'some', 'be', 'I’m', 'thank', 'because', 'if', 'that', 'but', 'into', 'them', \n",
        "        'came', 'just', 'then', 'come', 'know', 'they', 'could', 'little', 'there', 'day', 'make', 'us', 'did', 'many', 'very', 'end', 'new', 'want', 'from', 'not', 'were', 'get', 'of', 'what',\n",
        "        'goes', 'one', 'when', 'going', 'or', 'where', 'good', 'our', 'who', 'had', 'out', 'will', 'has', 'over', 'would','your' ]\n",
        "hf_S = ['after', 'have', 'please', 'all', 'her', 'saw', 'an', 'here', 'should', 'are', 'him', 'so', 'as', 'his', 'some', 'be', 'I’m', 'thank', 'because', 'if', 'that', 'but', 'into', 'them', \n",
        "        'came', 'just', 'then', 'come', 'know', 'they', 'could', 'little', 'there', 'day', 'make', 'us', 'did', 'many', 'very', 'end', 'new', 'want', 'from', 'not', 'were', 'get', 'of', 'what',\n",
        "        'goes', 'one', 'when', 'going', 'or', 'where', 'good', 'our', 'who', 'had', 'out', 'will', 'has', 'over', 'would','your' ]\n",
        "hf_T = ['also', 'animal', 'April', 'asked', 'August', 'books', 'brother', 'call', 'care', 'caught', 'caught', 'children', 'city', 'December', 'drink', 'eight', 'eleven',\n",
        "        'ever', 'father', 'favorite', 'February', 'found', 'Friday', 'friend', 'give', 'also', 'animal', 'April', 'asked', 'August', 'books', 'brother', 'call', 'care',\n",
        "        'caught', 'children', 'city', 'December', 'drink', 'eight', 'eleven', 'ever', 'father', 'favorite', 'February', 'found', 'Friday', 'friend', 'give', 'great', \n",
        "        'also' 'animal' 'April', 'asked', 'August', 'books', 'brother', 'call', 'care', 'caught', 'caught', 'children', 'city', 'December', 'drink', 'eight', 'eleven',\n",
        "        'ever', 'father', 'favorite', 'February', 'found', 'Friday', 'friend', 'give', 'great', 'gym', 'half', 'hour', 'hurt', 'January', 'July', 'June', 'kind', 'line', \n",
        "        'mail', 'March', 'May', 'maybe', 'Michigan', 'might', 'Monday', 'mother', 'must', 'night', 'nine', 'November', 'October', 'old', 'other', 'people', 'pretty', 'questions',\n",
        "        'rain', 'rest', 'same', 'Saturday', 'September', 'seven', 'sister', 'snow', 'something', 'stay', 'street', 'such', 'Sunday', 'sure', 'talk', 'teacher', 'tell', \n",
        "        'thing', 'Thursday', 'too', 'Tuesday', 'twelve', 'Wednesday', 'phone']\n"
      ],
      "metadata": {
        "id": "Gvf31s9c1B2s"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_list = hf_K + hf_F + hf_S + hf_T\n",
        "unique_list = list(set(combined_list))\n",
        "unique_list.sort()\n",
        "#print(unique_list)\n",
        "print(\"Total list of word that children learn as high frequency word from Kindergarten to Third Grade: \", len(unique_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsJ2-7-MQyA-",
        "outputId": "7b1de86f-b40e-4781-9c21-c8ddbbf7a113"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total list of word that children learn as high frequency word from Kindergarten to Third Grade:  181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) Count the ocurrence of each of the HF words in the text "
      ],
      "metadata": {
        "id": "P66eSFq8qDk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "filter_word = Counter(word_freq)\n",
        "counts = {word: filter_word[word] for word in combined_list}\n",
        "#print(counts)"
      ],
      "metadata": {
        "id": "u8S8PoUmVPr1"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_count = 0\n",
        "for key, value in counts.items():\n",
        "    total_count += value\n",
        "print(\"\\nTotal quantity of high frequency words in the text: \", total_count)\n",
        "print(\"\\nTotal words of text\", len(words))\n",
        "percentage = total_count/len(words)*100\n",
        "#print(\"\\nTotal words that belongs of the category high frequency words - 1 Grade: \", total)\n",
        "print(\"\\nTotal percentage of words:\", percentage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-bVWp2yVqRY",
        "outputId": "1b86da70-10e8-4099-ea3d-918abf7a6802"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total quantity of high frequency words in the text:  2102\n",
            "\n",
            "Total words of text 5522\n",
            "\n",
            "Total percentage of words: 38.06591814559942\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion:\n",
        "\n",
        "A child in third grade can read 38% of the text.\n",
        "\n",
        "Third grade is the year when kids go from 'learning to read' to 'reading to learn'. A 38% of the text is not enough.\n",
        "\n",
        "Reading proficiently by the end of third grade is a crucial marker in a child's educational development. Failure to read proficiently is linked to higher rates of school dropout.\n",
        "\n",
        "So, high frequency words and balanced literature didn't work to generate a proficient reader. \n"
      ],
      "metadata": {
        "id": "INjGuhj9qhos"
      }
    }
  ]
}