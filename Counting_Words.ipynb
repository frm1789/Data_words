{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhqoM6t934LM6XyKXxVV6M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frm1789/Data_words/blob/main/Counting_Words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iZl51X3_6i0",
        "outputId": "ff6845cf-324b-45ee-b65f-d6c02ecaa327"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary has  1103 keys\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def word_count(file_path):\n",
        "    word_counts = {}\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            words = re.findall(r'\\b\\w+\\b', line)\n",
        "            for word in words:\n",
        "                word_counts[word] = word_counts.get(word, 0) + 1\n",
        "    return word_counts\n",
        "\n",
        "file_path = \"text.txt\"\n",
        "word_counts = word_count(file_path)\n",
        "#print(word_counts)\n",
        "print(\"Dictionary has \", len(word_counts), \"keys\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import defaultdict\n",
        "from operator import itemgetter\n",
        "\n",
        "# Open the text file\n",
        "with open('text.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# Create an empty dictionary\n",
        "word_count = defaultdict(int)\n",
        "\n",
        "# Split the text into words and count the occurrences of each word\n",
        "for word in re.findall(r'\\b\\w+\\b', text):\n",
        "    word_count[word] += 1\n",
        "\n",
        "# Sort the dictionary alphabetically\n",
        "sorted_word_count = dict(sorted(word_count.items(), key=itemgetter(0)))\n",
        "\n",
        "# Count the number of elements in the dictionary\n",
        "elements_count = len(sorted_word_count)\n",
        "print(f\"\\nDictionary has {elements_count} elements.\")\n",
        "\n",
        "# Print the word count as a table\n",
        "# print('Word'.ljust(20), 'Count'.rjust(10))\n",
        "# print('-'*30)\n",
        "# for word, count in sorted_word_count.items():\n",
        "#    print(word.ljust(20), str(count).rjust(10))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO52K1Kqdwmf",
        "outputId": "aa392ad7-2cc1-4562-d837-767492b3c738"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dictionary has 1103 elements.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#remove word occuring less than 3 times \n",
        "for word in list(word_counts):\n",
        "    if word_counts[word] < 3:\n",
        "       del word_counts[word]\n",
        "\n",
        "#sorting the dictionary\n",
        "sorted_dict = dict(sorted(word_counts.items(), key=lambda item: item[1], reverse=True))\n",
        "\n",
        "\n",
        "# Count the number of elements in the dictionary\n",
        "elements_count = len(sorted_dict)\n",
        "print(f\"\\nDictionary has {elements_count} elements.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51gnRU8neVsk",
        "outputId": "100345f6-d42e-4b85-cfab-a96bcc9ecc23"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dictionary has 392 elements.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a dictionary with high frequency words\n",
        "high_frequency = {word: frequency for word, frequency in sorted_dict.items() if frequency >=10 }\n",
        "\n",
        "# Count the number of elements in the dictionary\n",
        "elements_count = len(high_frequency)\n",
        "print(f\"\\nDictionary has {elements_count} elements.\")\n",
        "\n",
        "\n",
        "print('Word'.ljust(20), 'Count'.rjust(10))\n",
        "print('-'*30)\n",
        "for word, count in high_frequency.items():\n",
        "    print(word.ljust(20), str(count).rjust(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K59FSq3amZaN",
        "outputId": "825bea75-3ae1-4858-fa93-e65381c3c3b3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dictionary has 102 elements.\n",
            "Word                      Count\n",
            "------------------------------\n",
            "the                         325\n",
            "Jack                        226\n",
            "Annie                       173\n",
            "said                        146\n",
            "He                          124\n",
            "to                          118\n",
            "was                          98\n",
            "a                            95\n",
            "The                          84\n",
            "his                          69\n",
            "of                           61\n",
            "s                            59\n",
            "and                          58\n",
            "at                           55\n",
            "tree                         55\n",
            "he                           54\n",
            "t                            51\n",
            "up                           48\n",
            "I                            48\n",
            "in                           47\n",
            "it                           46\n",
            "She                          45\n",
            "out                          44\n",
            "house                        43\n",
            "down                         37\n",
            "looked                       36\n",
            "her                          35\n",
            "on                           32\n",
            "she                          32\n",
            "you                          31\n",
            "book                         30\n",
            "dinosaur                     29\n",
            "And                          29\n",
            "back                         27\n",
            "Pteranodon                   26\n",
            "But                          25\n",
            "him                          24\n",
            "with                         23\n",
            "were                         23\n",
            "hill                         23\n",
            "A                            22\n",
            "into                         22\n",
            "for                          20\n",
            "started                      19\n",
            "window                       19\n",
            "creature                     19\n",
            "ladder                       18\n",
            "We                           18\n",
            "had                          17\n",
            "we                           17\n",
            "It                           15\n",
            "here                         15\n",
            "whispered                    15\n",
            "going                        15\n",
            "through                      15\n",
            "picture                      15\n",
            "off                          15\n",
            "woods                        14\n",
            "shouted                      14\n",
            "What                         14\n",
            "this                         14\n",
            "Tyrannosaurus                14\n",
            "real                         13\n",
            "time                         13\n",
            "about                        13\n",
            "go                           13\n",
            "books                        13\n",
            "ground                       13\n",
            "No                           12\n",
            "again                        12\n",
            "called                       12\n",
            "know                         12\n",
            "their                        12\n",
            "Henry                        12\n",
            "toward                       12\n",
            "Then                         12\n",
            "they                         12\n",
            "Don                          12\n",
            "over                         12\n",
            "magic                        12\n",
            "There                        11\n",
            "top                          11\n",
            "head                         11\n",
            "see                          11\n",
            "away                         11\n",
            "like                         11\n",
            "one                          11\n",
            "there                        11\n",
            "from                         11\n",
            "took                         11\n",
            "put                          11\n",
            "Oh                           10\n",
            "all                          10\n",
            "don                          10\n",
            "m                            10\n",
            "You                          10\n",
            "that                         10\n",
            "as                           10\n",
            "long                         10\n",
            "They                         10\n",
            "notebook                     10\n",
            "Go                           10\n"
          ]
        }
      ]
    }
  ]
}